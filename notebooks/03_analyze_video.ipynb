{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b4c91ece-c5b9-432e-ad68-c30f6bfd47c1",
   "metadata": {},
   "source": [
    "Analyze the Video Content → Find all scene changes.\n",
    "Extract Semantic Meaning from the Description → Understand what the user is asking.\n",
    "Match the Best Scene → Find the closest matching scene.\n",
    "Output the Start & End Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72edf1a-6987-4454-962e-48abce8eb6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"key.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7db5d7a-f094-4e4d-aabb-d5e2c358d49a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semantic-retriever@gcp-x-mlb-hackathon.iam.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "credentials, project = google.auth.default()\n",
    "print(getattr(credentials, \"service_account_email\", \"Using user credentials\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc77646-59ae-4341-8586-6644595d5c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install google-cloud-videointelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8efa96e3-2863-44be-8596-771a26c82cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes: [(0, 4), (5, 12), (12, 15), (15, 18)]\n",
      "Scene labels: [(0, 18, 'pitcher'), (0, 18, 'stadium'), (0, 18, 'player'), (0, 18, 'crowd'), (0, 18, 'audience'), (0, 18, 'baseball'), (0, 18, 'baseball player'), (0, 18, 'arena'), (0, 18, 'baseball positions'), (0, 18, 'home run'), (0, 18, 'pitch'), (0, 18, 'ball game'), (0, 18, 'bat and ball games'), (0, 18, 'games'), (0, 18, 'team sport'), (0, 18, 'baseball park'), (0, 18, 'baseball field'), (0, 18, 'sports'), (0, 18, 'sport venue')]\n",
      "Shot-level Labels: [(0, 4, 'pitcher', 0.9644664525985718), (12, 15, 'pitcher', 0.46593257784843445), (0, 4, 'player', 0.9449904561042786), (5, 12, 'player', 0.9447277784347534), (12, 15, 'player', 0.8705179691314697), (15, 18, 'player', 0.873670220375061), (5, 12, 'basketball', 0.5874577164649963), (0, 4, 'baseball umpire', 0.5114926099777222), (0, 4, 'baseball field', 0.9325483441352844), (12, 15, 'baseball field', 0.4231873154640198), (15, 18, 'baseball field', 0.7510219812393188), (0, 4, 'referee', 0.31523340940475464), (0, 4, 'team sport', 0.8525504469871521), (5, 12, 'team sport', 0.7962018847465515), (12, 15, 'team sport', 0.9796090722084045), (15, 18, 'team sport', 0.9304080009460449), (0, 4, 'baseball park', 0.9250723123550415), (15, 18, 'baseball park', 0.33747002482414246), (0, 4, 'games', 0.9330637454986572), (5, 12, 'games', 0.9733381271362305), (12, 15, 'games', 0.9341075420379639), (15, 18, 'games', 0.9599424600601196), (0, 4, 'ball game', 0.9314700365066528), (5, 12, 'ball game', 0.9489861726760864), (12, 15, 'ball game', 0.9489861726760864), (15, 18, 'ball game', 0.9489861726760864), (0, 4, 'bat and ball games', 0.9570661187171936), (5, 12, 'bat and ball games', 0.7558592557907104), (12, 15, 'bat and ball games', 0.968144953250885), (15, 18, 'bat and ball games', 0.7558592557907104), (0, 4, 'pitch', 0.8949780464172363), (0, 4, 'college baseball', 0.4851335287094116), (0, 4, 'sports', 0.978398859500885), (5, 12, 'sports', 0.9812172055244446), (12, 15, 'sports', 0.9871450662612915), (15, 18, 'sports', 0.978540301322937), (0, 4, 'sport venue', 0.8867999315261841), (5, 12, 'sport venue', 0.8409550786018372), (12, 15, 'sport venue', 0.9669921398162842), (15, 18, 'sport venue', 0.8044725060462952), (0, 4, 'baseball positions', 0.633383572101593), (12, 15, 'baseball positions', 0.3695678114891052), (5, 12, 'people', 0.467472642660141), (15, 18, 'ball', 0.3491884768009186), (0, 4, 'arena', 0.5028650164604187), (5, 12, 'arena', 0.7910177111625671), (15, 18, 'arena', 0.46444782614707947), (0, 4, 'baseball player', 0.9632939100265503), (12, 15, 'baseball player', 0.7896358370780945), (5, 12, 'scoreboard', 0.6186620593070984), (0, 4, 'baseball', 0.9974089860916138), (5, 12, 'baseball', 0.7352946996688843), (12, 15, 'baseball', 0.9951993227005005), (15, 18, 'baseball', 0.9539291262626648), (0, 4, 'dugout', 0.5786854028701782), (0, 4, 'catcher', 0.5828094482421875), (0, 4, 'infielder', 0.47402423620224), (0, 4, 'audience', 0.5017197728157043), (5, 12, 'audience', 0.9536385536193848), (12, 15, 'audience', 0.5937961935997009), (15, 18, 'audience', 0.5937961935997009), (0, 4, 'crowd', 0.5017532706260681), (5, 12, 'crowd', 0.9745272994041443), (12, 15, 'crowd', 0.6223902106285095), (15, 18, 'crowd', 0.5908024907112122), (0, 4, 'stadium', 0.6224387288093567), (5, 12, 'stadium', 0.8510870337486267), (15, 18, 'stadium', 0.61932772397995)]\n",
      "Frame-level Labels: []\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import videointelligence\n",
    "\n",
    "def analyze_video(video_uri):\n",
    "    client = videointelligence.VideoIntelligenceServiceClient()\n",
    "    features = [\n",
    "        videointelligence.Feature.SHOT_CHANGE_DETECTION,  # Scene boundaries\n",
    "        videointelligence.Feature.LABEL_DETECTION,         # Label detection (includes segment, shot, and frame-level)\n",
    "    ]\n",
    "\n",
    "    operation = client.annotate_video(input_uri=video_uri, features=features)\n",
    "    result = operation.result(timeout=300)\n",
    "\n",
    "    # Extract scene boundaries (shot annotations)\n",
    "    scenes = []\n",
    "    for shot in result.annotation_results[0].shot_annotations:\n",
    "        start_time = shot.start_time_offset.seconds\n",
    "        end_time = shot.end_time_offset.seconds\n",
    "        scenes.append((start_time, end_time))\n",
    "        \n",
    "    # Extract scene labels (objects/actions)\n",
    "    scene_labels = []\n",
    "    for label in result.annotation_results[0].segment_label_annotations:\n",
    "        for segment in label.segments:\n",
    "            scene_labels.append((segment.segment.start_time_offset.seconds, segment.segment.end_time_offset.seconds, label.entity.description))\n",
    "\n",
    "\n",
    "    # Extract shot-level labels (more precise per scene)\n",
    "    shot_labels = []\n",
    "    for label in result.annotation_results[0].shot_label_annotations:\n",
    "        for shot in label.segments:\n",
    "            shot_start = shot.segment.start_time_offset.seconds\n",
    "            shot_end = shot.segment.end_time_offset.seconds\n",
    "            # shot.confidence indicates the confidence level of the detected label.\n",
    "            shot_labels.append((shot_start, shot_end, label.entity.description, shot.confidence))\n",
    "\n",
    "    # Optionally, extract frame-level labels for even more granularity\n",
    "    frame_labels = []\n",
    "    for label in result.annotation_results[0].frame_label_annotations:\n",
    "        for frame in label.frames:\n",
    "            frame_time = frame.time_offset.seconds\n",
    "            frame_labels.append((frame_time, label.entity.description, frame.confidence))\n",
    "\n",
    "    return scenes, scene_labels, shot_labels, frame_labels\n",
    "\n",
    "# Example Usage\n",
    "video_url = \"gs://mlb_hackathon_bucket/videos/video.mp4\"\n",
    "scenes, scene_labels, shot_labels, frame_labels = analyze_video(video_url)\n",
    "\n",
    "print(\"Scenes:\", scenes)\n",
    "print(\"Scene labels:\", scene_labels)\n",
    "print(\"Shot-level Labels:\", shot_labels)\n",
    "print(\"Frame-level Labels:\", frame_labels)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0be05fe0-4eb1-4de6-8fb4-ba768514cfa9",
   "metadata": {},
   "source": [
    "Frame-level label annotations are optional and may not always be generated by the API. Here are a few reasons why you might be seeing an empty result at the frame level:\n",
    "\n",
    "Content Consistency:\n",
    "If your video content doesn't exhibit enough variation between individual frames (or the changes aren't significant enough), the API might not generate frame-level labels. The model may determine that shot- or segment-level annotations are sufficient for describing the content.\n",
    "\n",
    "Detection Confidence:\n",
    "The API only returns frame-level annotations when it’s confident about the detected labels at that granularity. If the confidence is low for individual frames, the result might be empty.\n",
    "\n",
    "Model Behavior:\n",
    "The Video Intelligence API is designed to return multiple levels of annotations (segment, shot, and frame) when available. However, for some videos, especially those with smoother transitions or minimal per-frame differences, frame-level annotations might not be populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af006569-535c-4e61-b8c4-88f85dd2461f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
